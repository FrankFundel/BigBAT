{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90944339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 14:29:34.015290: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-19 14:29:34.445273: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-19 14:29:37.209797: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ffundel/.local/lib:\n",
      "2022-12-19 14:29:37.210087: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ffundel/.local/lib:\n",
      "2022-12-19 14:29:37.210113: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from tools import prepare, mixup, preprocess, noise, getCorrects\n",
    "\n",
    "classes = {\n",
    "    \"Unlabeled\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49421f02",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b04dc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 8/8 [00:10<00:00,  1.28s/it]\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:04<00:00,  1.88it/s]\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:02<00:00,  3.00it/s]\n"
     ]
    }
   ],
   "source": [
    "num_bands = 257\n",
    "max_len = 60\n",
    "seq_len = (max_len + 1) * 2816      # = 250ms ~ 25ms (0.5 * 44 * (512 // 4))\n",
    "seq_skip = seq_len\n",
    "patch_len = 44\n",
    "patch_skip = 22\n",
    "\n",
    "data_path = \"./data/prepared_signal.h5\"\n",
    "X_train, Y_train, X_test, Y_test, X_val, Y_val = prepare(data_path, classes, seq_len, seq_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3017c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences: 7687\n",
      "Train sequences: (4612, 171776) (4612, 1)\n",
      "Test sequences: (1925, 171776) (1925, 1)\n",
      "Validation sequences: (1150, 171776) (1150, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total sequences:\", len(X_train) + len(X_test) + len(X_val))\n",
    "print(\"Train sequences:\", X_train.shape, Y_train.shape)\n",
    "print(\"Test sequences:\", X_test.shape, Y_test.shape)\n",
    "print(\"Validation sequences:\", X_val.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a791433",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "583d441d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ffundel/.local/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/ffundel/.local/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from torchsummary import summary\n",
    "from torchmetrics.functional import f1_score\n",
    "\n",
    "from SAM import SAM\n",
    "from ASL import AsymmetricLoss\n",
    "from BigBAT import BigBAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73946b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model, device_ids=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3294d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "class EmbedPretrain(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=(3, 5), stride=(2, 3), padding=3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=(3, 5), stride=(2, 3), padding=3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "    \n",
    "            nn.Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 3), padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 3), padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "    \n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.decode = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=(5, 5), stride=(2, 3), padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=(5, 7), stride=(2, 3), padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 3), padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 3), padding=(1, 2)),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(8, 1, kernel_size=(2, 3), stride=(2, 3), padding=(3, 5)),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encode(x)\n",
    "        x = self.decode(x)\n",
    "        return x\n",
    "\n",
    "model = EmbedPretrain().to(device)\n",
    "summary(model, (1, 44, 257))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc648dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 50\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1529c388",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.Tensor(X_train), torch.from_numpy(Y_train))\n",
    "test_data = TensorDataset(torch.Tensor(X_test), torch.from_numpy(Y_test))\n",
    "val_data = TensorDataset(torch.Tensor(X_val), torch.from_numpy(Y_val))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9e7e5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7ff2e83a3700>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#criterion = nn.L1Loss()\n",
    "\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "criterion = nn.MSELoss() # mean square error loss\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=lr, \n",
    "                             weight_decay=1e-5) # <--\n",
    "    \n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=5)\n",
    "scheduler = None\n",
    "\n",
    "min_val_loss = np.inf\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0630d19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, epoch, criterion, optimizer, scheduler, dataloader, device):\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    \n",
    "    for batch, (inputs, labels) in enumerate(tqdm(dataloader)):\n",
    "        # Transfer Data to GPU if available\n",
    "        inputs = inputs.to(device)\n",
    "        inputs = preprocess(inputs)\n",
    "        \n",
    "        inputs = inputs.unfold(dimension=1, size=patch_len, step=patch_skip).permute((0, 1, 3, 2)) # patches\n",
    "        b, n, w, h = inputs.shape\n",
    "        inputs = inputs.reshape((b * n, 1, w, h))\n",
    "         \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward Pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute Loss\n",
    "        loss = criterion(outputs, inputs)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate Loss\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "        # Perform learning rate step\n",
    "        #scheduler.step(epoch + batch / num_batches)\n",
    "            \n",
    "    epoch_loss = running_loss / num_samples\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c18c274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model, epoch, criterion, optimizer, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for batch, (inputs, labels) in enumerate(tqdm(dataloader)):\n",
    "            # Transfer Data to GPU if available\n",
    "            inputs = inputs.to(device)\n",
    "            inputs = preprocess(inputs)\n",
    "            \n",
    "            inputs = inputs.unfold(dimension=1, size=patch_len, step=patch_skip).permute((0, 1, 3, 2)) # patches\n",
    "            b, n, w, h = inputs.shape\n",
    "            inputs = inputs.reshape((b * n, 1, w, h))\n",
    "            num_samples = b * n\n",
    "        \n",
    "            # Clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward Pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute Loss\n",
    "            loss = criterion(outputs, inputs)\n",
    "\n",
    "            # Calculate Loss\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / num_samples\n",
    "    \n",
    "    a = np.random.randint(0, num_samples, 5)\n",
    "    return epoch_loss, inputs[a], outputs[a]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95cc47b",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23b94e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrankfundel\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "2022-12-19 14:30:35.374358: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-19 14:30:35.813919: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-19 14:30:37.987092: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ffundel/.local/lib:\n",
      "2022-12-19 14:30:37.987358: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ffundel/.local/lib:\n",
      "2022-12-19 14:30:37.987386: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ffundel/BigBAT/wandb/run-20221219_143031-3vgjzg68</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/frankfundel/BigBAT-pretrain/runs/3vgjzg68\" target=\"_blank\">eternal-mountain-15</a></strong> to <a href=\"https://wandb.ai/frankfundel/BigBAT-pretrain\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/frankfundel/BigBAT-pretrain/runs/3vgjzg68?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ff37848ce20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb_config = {\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": lr,\n",
    "    \"batch_size\": batch_size\n",
    "}\n",
    "\n",
    "wandb.init(project=\"BigBAT-pretrain\", entity=\"frankfundel\", config=wandb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2380367f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 0 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 145/145 [00:56<00:00,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 36/36 [00:03<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.1537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [32,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [33,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [34,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [35,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [36,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [37,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [38,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [39,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [40,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [41,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [42,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [43,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [44,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [45,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [46,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [47,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [48,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [49,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [50,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [51,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [52,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [53,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [54,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [55,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [56,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [57,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [58,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [59,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [60,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [61,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [62,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [63,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [64,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [65,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [66,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [67,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [68,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [69,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [70,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [71,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [72,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [73,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [74,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [75,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [76,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [77,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [78,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [79,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [80,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [81,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [82,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [83,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [84,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [85,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [86,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [87,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [88,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [89,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [90,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [91,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [92,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [93,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [94,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [114,0,0], thread: [95,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [96,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [97,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [98,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [99,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [100,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [101,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [102,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [103,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [104,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [105,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [106,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [107,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [108,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [109,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [110,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [111,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [112,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [113,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [114,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [115,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [116,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [117,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [118,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [119,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [120,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [121,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [122,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [123,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [124,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [125,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [126,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [154,0,0], thread: [127,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (44, 60, 257) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img, ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ins, axs):\n\u001b[0;32m---> 21\u001b[0m     \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrot90\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img, ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(outs, axs):\n",
      "File \u001b[0;32m/opt/Python/3.8.6/lib/python3.8/site-packages/matplotlib/__init__.py:1447\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1446\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1447\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1449\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1450\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1451\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m/opt/Python/3.8.6/lib/python3.8/site-packages/matplotlib/axes/_axes.py:5523\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5518\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[1;32m   5519\u001b[0m im \u001b[38;5;241m=\u001b[39m mimage\u001b[38;5;241m.\u001b[39mAxesImage(\u001b[38;5;28mself\u001b[39m, cmap, norm, interpolation, origin, extent,\n\u001b[1;32m   5520\u001b[0m                       filternorm\u001b[38;5;241m=\u001b[39mfilternorm, filterrad\u001b[38;5;241m=\u001b[39mfilterrad,\n\u001b[1;32m   5521\u001b[0m                       resample\u001b[38;5;241m=\u001b[39mresample, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5523\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5524\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5526\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[0;32m/opt/Python/3.8.6/lib/python3.8/site-packages/matplotlib/image.py:711\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A[:, :, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[0;32m--> 711\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    712\u001b[0m                     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    719\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (44, 60, 257) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_out = True\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    end = time.time()\n",
    "    print(f\"==================== Starting at epoch {epoch} ====================\", flush=True)\n",
    "    \n",
    "    train_loss = train_epoch(model, epoch, criterion, optimizer, scheduler, train_loader, device)\n",
    "    print('Training loss: {:.4f}'.format(train_loss), flush=True)\n",
    "    \n",
    "    val_loss, ins, outs = test_epoch(model, epoch, criterion, optimizer, val_loader, device)\n",
    "    print('Validation loss: {:.4f}'.format(val_loss), flush=True)\n",
    "    \n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "    })\n",
    "    \n",
    "    if show_out:\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=5, figsize=(10, 5))\n",
    "        for img, ax in zip(ins, axs):\n",
    "            ax.imshow(torch.rot90(img.cpu().squeeze(0)))\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=5, figsize=(10, 5))\n",
    "        for img, ax in zip(outs, axs):\n",
    "            ax.imshow(torch.rot90(img.cpu().squeeze(0)))\n",
    "        plt.show()\n",
    "    \n",
    "    if min_val_loss > val_loss:\n",
    "        print('val_loss decreased, saving model', flush=True)\n",
    "        min_val_loss = val_loss\n",
    "        \n",
    "        # Saving State Dict\n",
    "        torch.save(model.state_dict(), 'BigBAT-UFS-EAE.pth')\n",
    "\n",
    "# Load after training\n",
    "model.load_state_dict(torch.load('BigBAT-UFS-EAE.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15f57fc",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152db08d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
