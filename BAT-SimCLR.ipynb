{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90944339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-30 09:56:52.340758: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-30 09:56:52.787142: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-30 09:56:55.560669: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ffundel/.local/lib:\n",
      "2022-12-30 09:56:55.560952: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ffundel/.local/lib:\n",
      "2022-12-30 09:56:55.560979: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/ffundel/.local/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/ffundel/.local/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from tools import prepare, mixup, preprocess, noise, getCorrects\n",
    "from contrastive_learner import ContrastiveLearner\n",
    "from contrastive_learner.contrastive_learner import RandomApply\n",
    "\n",
    "\n",
    "classes = {\n",
    "    \"Rhinolophus ferrumequinum\": 0,\n",
    "    \"Rhinolophus hipposideros\": 1,\n",
    "    \"Myotis daubentonii\": 2,\n",
    "    \"Myotis brandtii\": 3,\n",
    "    \"Myotis mystacinus\": 4,\n",
    "    \"Myotis emarginatus\": 5,\n",
    "    \"Myotis nattereri\": 6,\n",
    "    #\"Myotis bechsteinii\": 7,\n",
    "    \"Myotis myotis\": 7,\n",
    "    \"Myotis dasycneme\": 8,\n",
    "    \"Nyctalus noctula\": 9,\n",
    "    \"Nyctalus leisleri\": 10,\n",
    "    \"Pipistrellus pipistrellus\": 11,\n",
    "    \"Pipistrellus nathusii\": 12,\n",
    "    \"Pipistrellus kuhlii\": 13,\n",
    "    \"Eptesicus serotinus\": 14,\n",
    "    \"Eptesicus nilssonii\": 15,\n",
    "    #\"Plecotus auritus\": 16,\n",
    "    #\"Plecotus austriacus\": 16,\n",
    "    #\"Barbastella barbastellus\": 16,\n",
    "    #\"Tadarida teniotis\": 16,\n",
    "    \"Miniopterus schreibersii\": 16,\n",
    "    #\"Hypsugo savii\": 18,\n",
    "    \"Vespertilio murinus\": 17,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49421f02",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b04dc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 22/22 [00:03<00:00,  6.24it/s]\n",
      "100%|███████████████████████████████████████████| 22/22 [00:01<00:00, 14.21it/s]\n",
      "100%|███████████████████████████████████████████| 22/22 [00:00<00:00, 24.03it/s]\n"
     ]
    }
   ],
   "source": [
    "num_bands = 257\n",
    "max_len = 60\n",
    "seq_len = (max_len + 1) * 2816      # = 250ms ~ 25ms (0.5 * 44 * (512 // 4))\n",
    "seq_skip = int(max_len / 4) * 2816     # 15 patches = 15 * 0.25 * 22050 * 0.5\n",
    "patch_len = 44\n",
    "patch_skip = 22\n",
    "\n",
    "data_path = \"../BAT/datasets/prepared_signal.h5\"\n",
    "X_train, Y_train, X_test, Y_test, X_val, Y_val = prepare(data_path, classes, seq_len, seq_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3017c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences: 19194\n",
      "Train sequences: (11323, 171776) (11323, 18)\n",
      "Test sequences: (4980, 171776) (4980, 18)\n",
      "Validation sequences: (2891, 171776) (2891, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total sequences:\", len(X_train) + len(X_test) + len(X_val))\n",
    "print(\"Train sequences:\", X_train.shape, Y_train.shape)\n",
    "print(\"Test sequences:\", X_test.shape, Y_test.shape)\n",
    "print(\"Validation sequences:\", X_val.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86b7f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse holdout for unsupervised training\n",
    "holdout = False\n",
    "if holdout:\n",
    "    h_split = 0.9\n",
    "    h_train = int(len(X_train) * h_split)\n",
    "    h_test = int(len(X_test) * h_split)\n",
    "    h_val = int(len(X_val) * h_split)\n",
    "    X_train = X_train[:h_train]\n",
    "    X_test = X_test[:h_test]\n",
    "    X_val = X_val[:h_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b75bed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences: 19194\n",
      "Train sequences: (11323, 171776) (11323, 18)\n",
      "Test sequences: (4980, 171776) (4980, 18)\n",
      "Validation sequences: (2891, 171776) (2891, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total sequences:\", len(X_train) + len(X_test) + len(X_val))\n",
    "print(\"Train sequences:\", X_train.shape, Y_train.shape)\n",
    "print(\"Test sequences:\", X_test.shape, Y_test.shape)\n",
    "print(\"Validation sequences:\", X_val.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a791433",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "583d441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from torchsummary import summary\n",
    "from torchmetrics.functional import f1_score\n",
    "\n",
    "from SAM import SAM\n",
    "from ASL import AsymmetricLoss\n",
    "from BigBAT_SimCLR import BigBAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73946b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model, device_ids=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67194844",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_patch_embedding = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=(3, 5), stride=(2, 3), padding=3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=(3, 5), stride=(2, 3), padding=3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "    \n",
    "            nn.Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 3), padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(kernel_size=5, stride=2, padding=1),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 3), padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "    \n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "#summary(big_patch_embedding, (1, 44, 257))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c857dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 64\n",
    "nhead = 2\n",
    "dim_feedforward = 32\n",
    "num_layers = 2\n",
    "dropout = 0.3\n",
    "classifier_dropout = 0.3\n",
    "num_classes = len(list(classes))\n",
    "\n",
    "BATencode = BigBAT(\n",
    "    max_len=max_len,\n",
    "    patch_len=patch_len,\n",
    "    patch_skip=patch_skip,\n",
    "    d_model=d_model,\n",
    "    num_classes=len(list(classes)),\n",
    "    patch_embedding=big_patch_embedding,\n",
    "    nhead=nhead,\n",
    "    dim_feedforward=dim_feedforward,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    classifier_dropout=classifier_dropout,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3294d8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContrastiveLearner(\n",
       "  (net): OutputHiddenLayer(\n",
       "    (net): BigBAT(\n",
       "      (patch_embedding): Sequential(\n",
       "        (0): Conv2d(1, 16, kernel_size=(3, 5), stride=(2, 3), padding=(3, 3))\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(16, 32, kernel_size=(3, 5), stride=(2, 3), padding=(3, 3))\n",
       "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "        (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (7): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 3), padding=(1, 1))\n",
       "        (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (9): ReLU()\n",
       "        (10): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 3), padding=(1, 1))\n",
       "        (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (12): ReLU()\n",
       "        (13): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (14): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (15): ReLU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (transformer_encoder): Transformer(\n",
       "        (layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): PreNorm(\n",
       "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Attention(\n",
       "                (attend): Softmax(dim=-1)\n",
       "                (dropout): Dropout(p=0.3, inplace=False)\n",
       "                (to_qkv): Linear(in_features=64, out_features=96, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=32, out_features=64, bias=True)\n",
       "                  (1): Dropout(p=0.3, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): PreNorm(\n",
       "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                  (2): Dropout(p=0.3, inplace=False)\n",
       "                  (3): Linear(in_features=32, out_features=64, bias=True)\n",
       "                  (4): Dropout(p=0.3, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): PreNorm(\n",
       "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Attention(\n",
       "                (attend): Softmax(dim=-1)\n",
       "                (dropout): Dropout(p=0.3, inplace=False)\n",
       "                (to_qkv): Linear(in_features=64, out_features=96, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=32, out_features=64, bias=True)\n",
       "                  (1): Dropout(p=0.3, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): PreNorm(\n",
       "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                  (2): Dropout(p=0.3, inplace=False)\n",
       "                  (3): Linear(in_features=32, out_features=64, bias=True)\n",
       "                  (4): Dropout(p=0.3, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): Sequential(\n",
       "        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=64, out_features=18, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (augment): Sequential(\n",
       "    (0): RandomApply(\n",
       "      (fn): ColorJitter(brightness=[0.19999999999999996, 1.8], contrast=[0.19999999999999996, 1.8], saturation=[0.19999999999999996, 1.8], hue=[-0.2, 0.2])\n",
       "    )\n",
       "    (1): RandomApply(\n",
       "      (fn): GaussianBlur(kernel_size=(3, 3), sigma=(1.5, 1.5))\n",
       "    )\n",
       "  )\n",
       "  (projection): Sequential(\n",
       "    (0): Linear(in_features=3904, out_features=3904, bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (2): Linear(in_features=3904, out_features=64, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "custom_augment_fn = nn.Sequential(\n",
    "    RandomApply(T.ColorJitter(0.8, 0.8, 0.8, 0.2), p=0.8),\n",
    "    #T.RandomHorizontalFlip(),\n",
    "    RandomApply(T.GaussianBlur((3, 3), (1.5, 1.5)), p=0.1),\n",
    "    #T.RandomResizedCrop((1343, 257))\n",
    ")\n",
    "\n",
    "model = ContrastiveLearner(\n",
    "    BATencode,\n",
    "    image_size = (1, 1343, 257),\n",
    "    hidden_layer = 'transformer_encoder',  # layer name where output is hidden dimension. this can also be an integer specifying the index of the child\n",
    "    project_hidden = True,     # use projection head\n",
    "    project_dim = 64,          # projection head dimensions\n",
    "    use_nt_xent_loss = True,   # the above mentioned loss, abbreviated\n",
    "    temperature = 0.1,         # temperature\n",
    "    augment_both = True,        # augment both query and key\n",
    "    augment_fn = custom_augment_fn\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc648dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 90\n",
    "epochs = 50\n",
    "lr = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1529c388",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.Tensor(X_train), torch.from_numpy(Y_train))\n",
    "test_data = TensorDataset(torch.Tensor(X_test), torch.from_numpy(Y_test))\n",
    "val_data = TensorDataset(torch.Tensor(X_val), torch.from_numpy(Y_val))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9e7e5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f04e85c8730>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = None\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=5)\n",
    "scheduler = None\n",
    "\n",
    "min_val_loss = np.inf\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0630d19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, epoch, criterion, optimizer, scheduler, dataloader, device):\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    \n",
    "    for batch, (inputs, labels) in enumerate(tqdm(dataloader)):\n",
    "        # Transfer Data to GPU if available\n",
    "        inputs = inputs.to(device)\n",
    "        inputs = preprocess(inputs).unsqueeze(1)\n",
    "         \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward Pass\n",
    "        loss = model(inputs)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate Loss\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "        # Perform learning rate step\n",
    "        #scheduler.step(epoch + batch / num_batches)\n",
    "            \n",
    "    epoch_loss = running_loss / num_samples\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c18c274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model, epoch, criterion, optimizer, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for batch, (inputs, labels) in enumerate(tqdm(dataloader)):\n",
    "            # Transfer Data to GPU if available\n",
    "            inputs = inputs.to(device)\n",
    "            inputs = preprocess(inputs).unsqueeze(1)\n",
    "                    \n",
    "            # Clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward Pass\n",
    "            loss = model(inputs)\n",
    "\n",
    "            # Calculate Loss\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / num_samples\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95cc47b",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23b94e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrankfundel\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "2022-12-30 09:57:57.863667: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-30 09:57:58.306777: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-30 09:58:00.494926: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ffundel/.local/lib:\n",
      "2022-12-30 09:58:00.495180: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ffundel/.local/lib:\n",
      "2022-12-30 09:58:00.495205: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ffundel/BigBAT/wandb/run-20221230_095753-mrnpyjpu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/frankfundel/BigBAT-pretrain/runs/mrnpyjpu\" target=\"_blank\">genial-oath-66</a></strong> to <a href=\"https://wandb.ai/frankfundel/BigBAT-pretrain\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/frankfundel/BigBAT-pretrain/runs/mrnpyjpu?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f03dc3304c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb_config = {\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": lr,\n",
    "    \"batch_size\": batch_size\n",
    "}\n",
    "\n",
    "wandb.init(project=\"BigBAT-pretrain\", entity=\"frankfundel\", config=wandb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2380367f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 0 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 126/126 [01:41<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 7.6652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 33/33 [00:07<00:00,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 15.6560\n",
      "val_loss decreased, saving model\n",
      "==================== Starting at epoch 1 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████| 126/126 [01:36<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.9142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 33/33 [00:06<00:00,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 37.8970\n",
      "==================== Starting at epoch 2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████| 126/126 [01:36<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.7647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 33/33 [00:06<00:00,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 12.4521\n",
      "val_loss decreased, saving model\n",
      "==================== Starting at epoch 3 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████| 126/126 [01:36<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.3462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 33/33 [00:06<00:00,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 9.6972\n",
      "val_loss decreased, saving model\n",
      "==================== Starting at epoch 4 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████| 126/126 [01:38<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.3248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 33/33 [00:06<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 28.3079\n",
      "==================== Starting at epoch 5 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████| 126/126 [01:38<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.4003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 33/33 [00:06<00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 19.9119\n",
      "==================== Starting at epoch 6 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|████▎                                     | 13/126 [00:09<01:28,  1.27it/s]"
     ]
    }
   ],
   "source": [
    "show_out = True\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    end = time.time()\n",
    "    print(f\"==================== Starting at epoch {epoch} ====================\", flush=True)\n",
    "    \n",
    "    train_loss = train_epoch(model, epoch, criterion, optimizer, scheduler, train_loader, device)\n",
    "    print('Training loss: {:.4f}'.format(train_loss), flush=True)\n",
    "    \n",
    "    val_loss = test_epoch(model, epoch, criterion, optimizer, val_loader, device)\n",
    "    print('Validation loss: {:.4f}'.format(val_loss), flush=True)\n",
    "    \n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "    })\n",
    "        \n",
    "    if min_val_loss > val_loss:\n",
    "        print('val_loss decreased, saving model', flush=True)\n",
    "        min_val_loss = val_loss\n",
    "        \n",
    "        # Saving State Dict\n",
    "        torch.save(model.net.state_dict(), 'BigBAT-SimCLR.pth')\n",
    "\n",
    "# Load after training\n",
    "model.net.load_state_dict(torch.load('BigBAT-SimCLR.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15f57fc",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac4d690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
